{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"], temperature = 0.6) #By default calls chatgpt 3.5\n",
    "\"\"\"# temperature lies b/w 0 and 1. the more towards one, the answers generated by it differs more. So, more creative.\n",
    "# More the value of temparature more risk (may generate wrong output)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Andhra Pradesh is Amaravati.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of Andhra Pradesh?\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Langchain\\Satwik\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id = \"google/flan-t5-base\", model_kwargs = {\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, if we see it is just a simple output. Not a full sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingface.predict(\"Plase write a poem on my girlfriend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "My love for her is strong and true\n",
      "A bond that will never be through\n",
      "I love her with all my heart\n",
      "No matter how far apart\n",
      "\n",
      "Our love is something to behold\n",
      "A bond that will never grow old\n",
      "We share a love that's so divine\n",
      "A love that will last through all time\n",
      "\n",
      "She's always so understanding and kind\n",
      "And I'm so thankful she's mine\n",
      "Her smile lights up my day\n",
      "And I'm so lucky in every way\n",
      "\n",
      "I love her more than words can say\n",
      "My love for her will never fade away\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Plase write a poem on my girlfriend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates and LLM Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(input_variables=['country'], template='Tell me the capital of this {country}')\n",
    "\n",
    "prompt_template.format(country = 'India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain #Combine the inputs and models - create a chain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt = prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple chains using simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template = \"Please tell me the capital of the {country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt = capital_prompt)\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-PfMj2NwDRq62JwF9AyteOett on requests per min. Limit: 3 / min. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Parliament House\n",
      "2. National Gallery of Australia\n",
      "3. Royal Australian Mint\n",
      "4. Australian War Memorial\n",
      "5. National Arboretum Canberra\n",
      "6. Telstra Tower\n",
      "7. Questacon\n",
      "8. Canberra Centre\n",
      "9. Mount Ainslie Lookout\n",
      "10. Cockington Green Gardens\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"Australia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Chain\n",
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template = \"Please tell me the capital of the {country}\")\n",
    "capital_chain = LLMChain(llm=llm, prompt = capital_prompt, output_key = \"capital\")\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables=['capital'],\n",
    "                               template=\"Suggest me some places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain, famous_chain], \n",
    "                        input_variables=['country'], \n",
    "                        output_variables=['capital', 'places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': '\\n\\n1. India Gate: This famous war memorial is a must-visit when in New Delhi.\\n\\n2. Red Fort: This 17th-century fort is a symbol of Mughal grandeur.\\n\\n3. Jama Masjid: This is India’s largest mosque and a popular tourist attraction.\\n\\n4. Qutub Minar: This UNESCO World Heritage Site is a 73-meter tall tower of victory.\\n\\n5. Humayun’s Tomb: This 16th-century tomb is an architectural marvel.\\n\\n6. Akshardham Temple: This is one of the largest Hindu temples in the world.\\n\\n7. Chandni Chowk: This bustling market is a great place to shop for souvenirs and local delicacies.\\n\\n8. Lodhi Gardens: This sprawling park is a great spot to relax and enjoy some peace and quiet.\\n\\n9. National Gallery of Modern Art: This museum is home to some of the best works of modern Indian art.\\n\\n10. Lotus Temple: This unique temple is a must-visit for its beautiful architecture.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':'India'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chatllm = ChatOpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"], temperature = 0.6, model = 'gpt-3.5-turbo') #By default calls chatgpt 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.6, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI go to comedy school? To learn how to crack the binary code!\"\\n\\n2. \"What do you call an AI that tells jokes? A pun-ning machine!\"\\n\\n3. \"Why did the AI start a stand-up comedy career? It wanted to make everyone LOLgorithm!\"\\n\\n4. \"Why did the AI become a comedian? It wanted to break the ice… and then calculate the exact temperature!\"\\n\\n5. \"What do you get when you cross an AI with a comedian? A byte-sized bundle of laughter!\"\\n\\n6. \"Why did the AI bomb at the comedy club? Its timing was a bit binary, 0s and 1s!\"\\n\\n7. \"Why did the AI get kicked off stage during its comedy routine? It kept telling \\'byte\\'-sized jokes!\"\\n\\n8. \"How does an AI make its audience laugh? It runs a \\'humor\\' algorithm that computes hilarious punchlines!\"\\n\\n9. \"What did the AI say to the audience at the comedy show? \\'01010101 01000101 01000011 01000001 01001110 01010100 00100000 01001101 01000101 01000001 01001110 00100000 01001111 01001110 00100001\\'\"\\n\\n10. \"Why did the AI\\'s comedy show get such rave reviews? It had the \\'intelligence\\' to deliver the \\'artificial\\' laughs!\"')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#System message - How do you want system to act like?\n",
    "#HumanMessage - Actual input\n",
    "Chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseparatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System template\n",
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 words synonyms in a comma separated list\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaining up\n",
    "chain = chatprompt|Chatllm|Commaseparatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' wise', ' sharp']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Satwik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
